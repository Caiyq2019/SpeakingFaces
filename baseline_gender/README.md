This folder contains a code for training multimodal gender classification model using audio, visual (rgb) and thermal images.

The baseline model is built using SpeakingFaces database which contains over 100 subjects and each subject utteraring around 100 short commands.

The model architecture and specification details are given in *model.py* file.
The hyper-parameter values are given in *options.py* file.
To start training and testing the model, please see *main.py* file.
